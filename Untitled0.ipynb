{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNuGWR5klYM6wbx2KL+ieFT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enjun/Building-Machine-Learning-Projects-with-TensorFlow/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUmFC7dq0b13",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "59277fdc-7c5f-4df6-9c84-629be17e1391"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "# Adds a densely-connected layer with 64 units to the model:\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "# Add another:\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "# Add an output layer with 10 output units:\n",
        "model.add(layers.Dense(10))\n",
        "# Create a relu layer:\n",
        "layers.Dense(64, activation='relu')\n",
        "# Or:\n",
        "layers.Dense(64, activation=tf.nn.relu)\n",
        "\n",
        "# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
        "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
        "model = tf.keras.Sequential([\n",
        "# Adds a densely-connected layer with 64 units to the model:\n",
        "layers.Dense(64, activation='relu', input_shape=(32,)),\n",
        "# Add another:\n",
        "layers.Dense(64, activation='relu'),\n",
        "# Add an output layer with 10 output units:\n",
        "layers.Dense(10)])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "# Configure a model for mean-squared error regression.\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "              loss='mse',       # mean squared error\n",
        "              metrics=['mae'])  # mean absolute error\n",
        "\n",
        "# Configure a model for categorical classification.\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "data = np.random.random((1000, 32))\n",
        "labels = np.random.random((1000, 10))\n",
        "\n",
        "model.fit(data, labels, epochs=10, batch_size=32)\n",
        "# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\n",
        "layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "\n",
        "# A linear layer with a kernel initialized to a random orthogonal matrix:\n",
        "import numpy as np\n",
        "\n",
        "data = np.random.random((1000, 32))\n",
        "labels = np.random.random((1000, 10))\n",
        "\n",
        "val_data = np.random.random((100, 32))\n",
        "val_labels = np.random.random((100, 10))\n",
        "\n",
        "model.fit(data, labels, epochs=10, batch_size=32,\n",
        "          validation_data=(val_data, val_labels))\n",
        "\n",
        "# Instantiates a toy dataset instance:\n",
        "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
        "dataset = dataset.batch(32)\n",
        "\n",
        "model.fit(dataset, epochs=10)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
        "dataset = dataset.batch(32)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\n",
        "val_dataset = val_dataset.batch(32)\n",
        "\n",
        "model.fit(dataset, epochs=10,\n",
        "          validation_data=val_dataset)\n",
        "\n",
        "# With Numpy arrays\n",
        "data = np.random.random((1000, 32))\n",
        "labels = np.random.random((1000, 10))\n",
        "\n",
        "model.evaluate(data, labels, batch_size=32)\n",
        "\n",
        "# With a Dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
        "dataset = dataset.batch(32)\n",
        "\n",
        "model.evaluate(dataset)\n",
        "\n",
        "result = model.predict(data, batch_size=32)\n",
        "print(result.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "layers.Dense(64, kernel_initializer='orthogonal')\n",
        "\n",
        "# A linear layer with a bias vector initialized to 2.0s:\n",
        "layers.Dense(64, bias_initializer=tf.keras.initializers.Constant(2.0))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 270.0450 - accuracy: 0.1090\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 1121.7349 - accuracy: 0.0760\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 2242.9492 - accuracy: 0.1120\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 3807.1345 - accuracy: 0.1020\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 5530.8799 - accuracy: 0.1190\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 8070.2930 - accuracy: 0.0970\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 10465.0947 - accuracy: 0.1010\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 13275.1270 - accuracy: 0.0960\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 16578.3789 - accuracy: 0.0910\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 19983.9453 - accuracy: 0.1190\n",
            "Epoch 1/10\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 23849.7578 - accuracy: 0.1090 - val_loss: 29017.7168 - val_accuracy: 0.1100\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 27963.4531 - accuracy: 0.1060 - val_loss: 40069.3867 - val_accuracy: 0.0500\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 31876.9844 - accuracy: 0.1140 - val_loss: 28002.5879 - val_accuracy: 0.1500\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 37877.5469 - accuracy: 0.1090 - val_loss: 31054.9805 - val_accuracy: 0.0800\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 41568.4141 - accuracy: 0.0970 - val_loss: 44628.5039 - val_accuracy: 0.1500\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 47416.7812 - accuracy: 0.1050 - val_loss: 76324.3125 - val_accuracy: 0.0900\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 53139.2812 - accuracy: 0.0990 - val_loss: 53029.9766 - val_accuracy: 0.0500\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 59121.5664 - accuracy: 0.1050 - val_loss: 46114.5664 - val_accuracy: 0.1500\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 64804.4102 - accuracy: 0.0960 - val_loss: 80875.8438 - val_accuracy: 0.0800\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 72727.7891 - accuracy: 0.0830 - val_loss: 129144.9766 - val_accuracy: 0.0800\n",
            "Epoch 1/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 80634.6719 - accuracy: 0.1060\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 88288.0078 - accuracy: 0.1010\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 92837.6484 - accuracy: 0.1110\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 102258.7266 - accuracy: 0.0960\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 112285.9922 - accuracy: 0.0970\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 117148.5547 - accuracy: 0.0870\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 127577.8047 - accuracy: 0.0920\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 135812.6875 - accuracy: 0.0930\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 146299.4219 - accuracy: 0.0940\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 156596.0781 - accuracy: 0.0890\n",
            "Epoch 1/10\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 167804.0938 - accuracy: 0.1110 - val_loss: 229660.0469 - val_accuracy: 0.1000\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 178195.4844 - accuracy: 0.0970 - val_loss: 242821.5625 - val_accuracy: 0.1000\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 189803.8906 - accuracy: 0.0990 - val_loss: 235755.7812 - val_accuracy: 0.1500\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 202941.0625 - accuracy: 0.0890 - val_loss: 258372.9219 - val_accuracy: 0.0900\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 205417.6875 - accuracy: 0.1020 - val_loss: 285958.5625 - val_accuracy: 0.0900\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 218608.5000 - accuracy: 0.0870 - val_loss: 202555.1250 - val_accuracy: 0.1100\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 231934.7500 - accuracy: 0.0920 - val_loss: 235597.0938 - val_accuracy: 0.1100\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 246038.6875 - accuracy: 0.0860 - val_loss: 235021.8125 - val_accuracy: 0.1500\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 251122.5312 - accuracy: 0.1220 - val_loss: 342389.4375 - val_accuracy: 0.1500\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 268420.3750 - accuracy: 0.0950 - val_loss: 363896.7188 - val_accuracy: 0.0800\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 361249.0312 - accuracy: 0.0910\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 361249.0312 - accuracy: 0.0910\n",
            "(1000, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.core.Dense at 0x7fdc719494a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    }
  ]
}